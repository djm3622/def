{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce169423-3e3a-44f0-b38d-cb69e8aa6bf4",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Notebook for distriputed training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013afb49-8586-42ba-baca-e639baf1d16f",
   "metadata": {},
   "source": [
    "# Imports/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79ece1a5-285a-4c11-861f-a6844f3ddd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 17:33:46.299468: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-24 17:33:46.314532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-24 17:33:46.333056: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-24 17:33:46.338714: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-24 17:33:46.352928: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-24 17:33:47.261854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator, notebook_launcher\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wandb_helper import init_wandb, save_model_architecture, finish_run\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from safetensors.torch import load_file\n",
    "from diffusers import UNet2DModel\n",
    "import data\n",
    "import dataset\n",
    "import model\n",
    "import training\n",
    "import math\n",
    "import utility\n",
    "import op_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f52713-7c77-4e60-900c-acd9ee1bdf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:    \n",
    "    # dataset\n",
    "    path = '/data/users/jupyter-dam724/colliding_solutions'\n",
    "    solver = 'ros2'\n",
    "    fixed_seq_len = 216\n",
    "    ahead = 3\n",
    "    tail = 1\n",
    "    aug = False\n",
    "    upsample_size = 96\n",
    "\n",
    "    # device (not used but needed for dataset)\n",
    "    device_pref = 'cuda'\n",
    "    device_ind = None\n",
    "    \n",
    "    # distributed training\n",
    "    num_processes = 2\n",
    "    per_gpu_batch_size = 32\n",
    "    total_batch_size = per_gpu_batch_size * num_processes # (temporarily removed)\n",
    "    workers_per_gpu = 6\n",
    "    tworkers = workers_per_gpu * num_processes\n",
    "    vworkers = workers_per_gpu * num_processes\n",
    "    grad_accumulate = 1\n",
    "    \n",
    "    # optimization\n",
    "    base_lr = 1e-5\n",
    "    max_lr = 1e-4\n",
    "    lr = base_lr * math.sqrt(total_batch_size / (per_gpu_batch_size))  # sqrt scaling\n",
    "    \n",
    "    # training\n",
    "    epoches = 40\n",
    "    timesteps = 4000\n",
    "    loss_type = \"simple\"\n",
    "    val_delay = 1\n",
    "    patience = 50\n",
    "    \n",
    "    # experimentations\n",
    "    project_name = \"Operator Guided Diffusion\"\n",
    "    experiment_name = 'operator-training-big-multistep-nodrop'\n",
    "    save_path = f'/data/users/jupyter-dam724/time-invariant-operator/checkpoint/{experiment_name}/'\n",
    "    utility.validate_and_create_save_path(save_path, experiment_name)\n",
    "    \n",
    "    experiment_name = 'operator-training-big-multistep-lowerdropout'\n",
    "    tset = 'valid'\n",
    "    from_checkpoint = f'/data/users/jupyter-dam724/time-invariant-operator/checkpoint/{experiment_name}/{tset}/model.safetensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3860894-725c-43a6-903b-bf3082685b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavid724\u001b[0m (\u001b[33mdavid724-lehigh-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/users/jupyter-dam724/time-invariant-operator/wandb/run-20250124_173406-y8rxeqs7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/david724-lehigh-university/Operator%20Guided%20Diffusion/runs/y8rxeqs7' target=\"_blank\">operator-training-big-multistep-lowerdropout</a></strong> to <a href='https://wandb.ai/david724-lehigh-university/Operator%20Guided%20Diffusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/david724-lehigh-university/Operator%20Guided%20Diffusion' target=\"_blank\">https://wandb.ai/david724-lehigh-university/Operator%20Guided%20Diffusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/david724-lehigh-university/Operator%20Guided%20Diffusion/runs/y8rxeqs7' target=\"_blank\">https://wandb.ai/david724-lehigh-university/Operator%20Guided%20Diffusion/runs/y8rxeqs7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    }
   ],
   "source": [
    "init_wandb(\n",
    "    project_name=Config.project_name,\n",
    "    run_name=Config.experiment_name,\n",
    "    config_class=Config,\n",
    "    save_path=Config.save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831c777-4f2e-4d41-b9fb-d991260fe134",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868124c4-2043-4813-a2b0-6e9c2131b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acelerate_ddp():\n",
    "    accelerator = Accelerator(gradient_accumulation_steps=Config.grad_accumulate)\n",
    "    \n",
    "    data_params = {\n",
    "        'path': Config.path, \n",
    "        'device_pref': Config.device_pref, \n",
    "        'solver': Config.solver, \n",
    "        'fixed_seq_len': Config.fixed_seq_len, \n",
    "        'ahead': Config.ahead, \n",
    "        'tail': Config.tail,\n",
    "        'device_ind': Config.device_ind\n",
    "    }\n",
    "\n",
    "    _, (x_train_data, y_train_data), (x_valid_data, y_valid_data) = data.main(**data_params)\n",
    "\n",
    "    dataset_params = {\n",
    "        'x_train_data': x_train_data, \n",
    "        'y_train_data': y_train_data, \n",
    "        'x_valid_data': x_valid_data, \n",
    "        'y_valid_data': y_valid_data, \n",
    "        'batch_size': Config.total_batch_size,\n",
    "        'tworkers': Config.tworkers, \n",
    "        'vworkers': Config.vworkers,\n",
    "        'upsample_size': Config.upsample_size,\n",
    "        'aug': Config.aug\n",
    "    }\n",
    "\n",
    "    train_dl, valid_dl = dataset.main_operator(**dataset_params)\n",
    "    \n",
    "    unet = UNet2DModel(\n",
    "        sample_size=(Config.upsample_size, Config.upsample_size),        \n",
    "        in_channels=3,         \n",
    "        out_channels=1,         \n",
    "        layers_per_block=2,      \n",
    "        block_out_channels=(64, 128, 256, 256),  \n",
    "        down_block_types=(\n",
    "            \"DownBlock2D\",      # 64 channels at 96x96\n",
    "            \"DownBlock2D\",      # 64 channels at 48x48\n",
    "            \"AttnDownBlock2D\",  # 128 channels at 24x24\n",
    "            \"AttnDownBlock2D\"   # 64 channels at 12x12\n",
    "        ),\n",
    "        up_block_types=(\n",
    "            \"AttnUpBlock2D\",\n",
    "            \"AttnUpBlock2D\",\n",
    "            \"UpBlock2D\",\n",
    "            \"UpBlock2D\"\n",
    "        ),\n",
    "        dropout=0.0\n",
    "    )\n",
    "    \n",
    "    save_model_architecture(unet, Config.save_path)\n",
    "    \n",
    "    if Config.from_checkpoint is not None:\n",
    "        state_dict = load_file(Config.from_checkpoint)\n",
    "        model.load_model_weights(unet, state_dict)\n",
    "\n",
    "    optimizer = optim.AdamW(unet.parameters(), lr=Config.lr)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=Config.max_lr,\n",
    "        epochs=Config.epoches,\n",
    "        steps_per_epoch=len(train_dl),\n",
    "        pct_start=0.25,  \n",
    "        div_factor=1e4,  \n",
    "        final_div_factor=1e4 \n",
    "    )\n",
    "    \n",
    "    # Send everything through `accelerator.prepare`\n",
    "    train_dl, valid_dl, unet, optimizer, scheduler = accelerator.prepare(\n",
    "        train_dl, valid_dl, unet, optimizer, scheduler\n",
    "    )\n",
    "        \n",
    "    train_log, valid_log = [], []\n",
    "    \n",
    "    training_params = {\n",
    "        'accelerator': accelerator,\n",
    "        'train': train_dl, \n",
    "        'valid': valid_dl, \n",
    "        'model': unet, \n",
    "        'epochs': Config.epoches, \n",
    "        'patience': Config.patience, \n",
    "        'criterion': model.OperatorLoss(0.5, 0.5), \n",
    "        'save_path': Config.save_path, \n",
    "        'train_log': train_log, \n",
    "        'valid_log': valid_log, \n",
    "        'optimizer': optimizer, \n",
    "        'scheduler': scheduler, \n",
    "        'loading_bar': False,\n",
    "        'val_delay': Config.val_delay\n",
    "    }\n",
    "    \n",
    "    op_train.accelerator_train_operator(**training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a92728c-f611-4fdc-a233-21716cd4c8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n",
      "Now using GPU.\n",
      "Now using GPU.\n",
      "Train size: 143697, Percent of toal: 74.68%, Unique instances: 700\n",
      "Train size: 48714, Percent of toal: 25.32%, Unique instances: 240\n",
      "Train size: 143697, Percent of toal: 74.68%, Unique instances: 700\n",
      "Train size: 48714, Percent of toal: 25.32%, Unique instances: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [256, 512, 1, 1], strides() = [512, 1, 512, 512]\n",
      "bucket_view.sizes() = [256, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/data/users/jupyter-dam724/.local/lib/python3.9/site-packages/torch/autograd/graph.py:825: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [256, 512, 1, 1], strides() = [512, 1, 512, 512]\n",
      "bucket_view.sizes() = [256, 512, 1, 1], strides() = [512, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Train Loss: 0.909004807472229, Validation Loss: 1.0518529415130615\n",
      "Epoch 2/40, Train Loss: 0.8876733779907227, Validation Loss: 1.0355528593063354\n",
      "Epoch 3/40, Train Loss: 0.8724039793014526, Validation Loss: 1.022350549697876\n",
      "Epoch 4/40, Train Loss: 0.8645174503326416, Validation Loss: 1.015981912612915\n",
      "Epoch 5/40, Train Loss: 0.8661057353019714, Validation Loss: 1.0313947200775146\n",
      "Epoch 6/40, Train Loss: 0.8744868040084839, Validation Loss: 1.0546786785125732\n",
      "Epoch 7/40, Train Loss: 0.8850003480911255, Validation Loss: 1.0320265293121338\n",
      "Epoch 8/40, Train Loss: 0.8937674760818481, Validation Loss: 1.0396535396575928\n",
      "Epoch 9/40, Train Loss: 0.8928471803665161, Validation Loss: 1.0770690441131592\n",
      "Epoch 10/40, Train Loss: 0.8860424160957336, Validation Loss: 1.0214364528656006\n",
      "Epoch 11/40, Train Loss: 0.867950975894928, Validation Loss: 1.0171575546264648\n",
      "Epoch 12/40, Train Loss: 0.8480733633041382, Validation Loss: 0.9687395691871643\n",
      "Epoch 13/40, Train Loss: 0.8302755355834961, Validation Loss: 1.0055034160614014\n",
      "Epoch 14/40, Train Loss: 0.8122074604034424, Validation Loss: 0.9616214036941528\n",
      "Epoch 15/40, Train Loss: 0.7940012812614441, Validation Loss: 0.9670483469963074\n",
      "Epoch 16/40, Train Loss: 0.776057243347168, Validation Loss: 0.9558666944503784\n",
      "Epoch 17/40, Train Loss: 0.7574183344841003, Validation Loss: 1.0083234310150146\n",
      "Epoch 18/40, Train Loss: 0.739100456237793, Validation Loss: 0.9376863241195679\n",
      "Epoch 19/40, Train Loss: 0.7221704721450806, Validation Loss: 0.9119888544082642\n",
      "Epoch 20/40, Train Loss: 0.7031388282775879, Validation Loss: 0.9216781854629517\n",
      "Epoch 21/40, Train Loss: 0.686458945274353, Validation Loss: 0.9079418182373047\n",
      "Epoch 22/40, Train Loss: 0.6693110466003418, Validation Loss: 0.9229089021682739\n",
      "Epoch 23/40, Train Loss: 0.6529425382614136, Validation Loss: 0.9332281351089478\n",
      "Epoch 24/40, Train Loss: 0.6383610963821411, Validation Loss: 0.899342954158783\n",
      "Epoch 25/40, Train Loss: 0.623390793800354, Validation Loss: 0.8948649168014526\n",
      "Epoch 26/40, Train Loss: 0.6088676452636719, Validation Loss: 0.895897388458252\n",
      "Epoch 27/40, Train Loss: 0.5955814123153687, Validation Loss: 0.8855600357055664\n",
      "Epoch 28/40, Train Loss: 0.582777738571167, Validation Loss: 0.8866356611251831\n",
      "Epoch 29/40, Train Loss: 0.5704973936080933, Validation Loss: 0.8885090351104736\n",
      "Epoch 30/40, Train Loss: 0.5602403283119202, Validation Loss: 0.8843463659286499\n",
      "Epoch 31/40, Train Loss: 0.5498795509338379, Validation Loss: 0.8876986503601074\n",
      "Epoch 32/40, Train Loss: 0.5403330326080322, Validation Loss: 0.8853811025619507\n",
      "Epoch 33/40, Train Loss: 0.5322416424751282, Validation Loss: 0.887833833694458\n",
      "Epoch 34/40, Train Loss: 0.5250451564788818, Validation Loss: 0.8885523080825806\n",
      "Epoch 35/40, Train Loss: 0.5188547372817993, Validation Loss: 0.8891147375106812\n",
      "Epoch 36/40, Train Loss: 0.5141305923461914, Validation Loss: 0.8901948928833008\n",
      "Epoch 37/40, Train Loss: 0.5104926824569702, Validation Loss: 0.8913764953613281\n",
      "Epoch 38/40, Train Loss: 0.5080631971359253, Validation Loss: 0.8924245238304138\n",
      "Epoch 39/40, Train Loss: 0.5065140128135681, Validation Loss: 0.8922932744026184\n",
      "Epoch 40/40, Train Loss: 0.5057837963104248, Validation Loss: 0.8924539089202881\n"
     ]
    }
   ],
   "source": [
    "notebook_launcher(acelerate_ddp, args=(), num_processes=Config.num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f12842-7e2d-4308-abb5-90c237840b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b77e5d3a02849fd83e2a413797f2204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.021 MB of 0.021 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>██▇▇▇▇████▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_loss</td><td>▇▆▆▆▆▇▆▇█▆▆▄▅▄▄▄▆▃▂▂▂▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>model_architecture</td><td>UNet2DModel(\n",
       "  (conv...</td></tr><tr><td>train_loss</td><td>0.50578</td></tr><tr><td>valid_loss</td><td>0.89245</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">operator-training-big-multistep-lowerdropout</strong> at: <a href='https://wandb.ai/david724-lehigh-university/Operator%20Guided%20Diffusion/runs/y8rxeqs7' target=\"_blank\">https://wandb.ai/david724-lehigh-university/Operator%20Guided%20Diffusion/runs/y8rxeqs7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250124_173406-y8rxeqs7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finish_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0009e0-66dc-4df5-af38-4119c5c6cbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
